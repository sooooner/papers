공부한 논문들을 요약 정리 해놓은 저장소 입니다. 

## Understanding, Generalization, Transfer

1. Hinton, Geoffrey, Oriol Vinyals, and Jeff Dean. "Distilling the knowledge in a neural network." arXiv preprint arXiv:1503.02531 (2015). [[review link](https://github.com/sooooner/papers/issues/6)]
2. Nguyen, Anh, Jason Yosinski, and Jeff Clune. "Deep neural networks are easily fooled: High confidence predictions for unrecognizable images." Proceedings of the IEEE conference on computer vision and pattern recognition. 2015. [[review link](https://github.com/sooooner/papers/issues/9)]
3. Yosinski, Jason, et al. "How transferable are features in deep neural networks?." Advances in neural information processing systems. 2014. [[review link](https://github.com/sooooner/papers/issues/10)]
4. Sharif Razavian, Ali, et al. "CNN features off-the-shelf: an astounding baseline for recognition." Proceedings of the IEEE conference on computer vision and pattern recognition workshops. 2014. [[review link](https://github.com/sooooner/papers/issues/11)]
5. Oquab, Maxime, et al. "Learning and transferring mid-level image representations using convolutional neural networks." Proceedings of the IEEE conference on computer vision and pattern recognition. 2014. [[review link](https://github.com/sooooner/papers/issues/12)]
6. Donahue, Jeff, et al. "Decaf: A deep convolutional activation feature for generic visual recognition." International conference on machine learning. 2014. [[link]()]
7. Zeiler, Matthew D., and Rob Fergus. "Visualizing and understanding convolutional networks." European conference on computer vision. Springer, Cham, 2014. [[review link](https://github.com/sooooner/papers/issues/13)]


## Optimization / Training Techniques

1. Srivastava, Rupesh K., Klaus Greff, and Jürgen Schmidhuber. "Training very deep networks." Advances in neural information processing systems 28 (2015): 2377-2385. [[review link](https://github.com/sooooner/papers/issues/14)]
2. Kingma, Diederik P., and Jimmy Ba. "Adam: A method for stochastic optimization." arXiv preprint arXiv:1412.6980 (2014). [[review link](https://github.com/sooooner/papers/issues/15)]
3. Srivastava, Nitish, et al. "Dropout: a simple way to prevent neural networks from overfitting." The journal of machine learning research 15.1 (2014): 1929-1958. [[review link](https://github.com/sooooner/papers/issues/17)]
4. Ioffe, Sergey, and Christian Szegedy. "Batch normalization: Accelerating deep network training by reducing internal covariate shift." arXiv preprint arXiv:1502.03167 (2015). [[review link](https://github.com/sooooner/papers/issues/18)]
5. Bergstra, James, and Yoshua Bengio. "Random search for hyper-parameter optimization." The Journal of Machine Learning Research 13.1 (2012): 281-305. [[review link](https://github.com/sooooner/papers/issues/19)]
6. Hinton, Geoffrey E., et al. "Improving neural networks by preventing co-adaptation of feature detectors." arXiv preprint arXiv:1207.0580 (2012). [[review link](https://github.com/sooooner/papers/issues/20)]
7. He, Kaiming, et al. "Delving deep into rectifiers: Surpassing human-level performance on imagenet classification." Proceedings of the IEEE international conference on computer vision. 2015. [[review link](https://github.com/sooooner/papers/issues/31)]
8. Andrychowicz, Marcin, et al. "Learning to learn by gradient descent by gradient descent." Advances in neural information processing systems 29 (2016): 3981-3989. [[review link](https://github.com/sooooner/papers/issues/50)]

## Vision

1. Uijlings, Jasper RR, et al. "Selective search for object recognition." International journal of computer vision 104.2 (2013): 154-171. [[review link](https://github.com/sooooner/papers/issues/22)]
2. Felzenszwalb, Pedro F., and Daniel P. Huttenlocher. "Efficient graph-based image segmentation." International journal of computer vision 59.2 (2004): 167-181. [[review link](https://github.com/sooooner/papers/issues/23)]
3. Lowe, David G. "Object recognition from local scale-invariant features." Proceedings of the seventh IEEE international conference on computer vision. Vol. 2. Ieee, 1999. [[link]()]
4. Dai, Jifeng, et al. "Deformable convolutional networks." Proceedings of the IEEE international conference on computer vision. 2017. [[review link](https://github.com/sooooner/papers/issues/3)]
5. Achanta, Radhakrishna, et al. "SLIC superpixels compared to state-of-the-art superpixel methods." IEEE transactions on pattern analysis and machine intelligence 34.11 (2012): 2274-2282. [[review link](https://github.com/sooooner/papers/issues/24)]
6. Pavlic, Mario, Gerhard Rigoll, and Slobodan Ilic. "Classification of images in fog and fog-free scenes for use in vehicles." 2013 IEEE Intelligent Vehicles Symposium (IV). IEEE, 2013. [[link]()]
7. Guerra, Jose Carlos Villarreal, et al. "Weather Classification: A new multi-class dataset, data augmentation approach and comprehensive evaluations of Convolutional Neural Networks." 2018 NASA/ESA Conference on Adaptive Hardware and Systems (AHS). IEEE, 2018. [[review link](https://github.com/sooooner/papers/issues/25)]
8. Simonyan, Karen, and Andrew Zisserman. "Very deep convolutional networks for large-scale image recognition." arXiv preprint arXiv:1409.1556 (2014). [[review link](https://github.com/sooooner/papers/issues/26)]
9. Krizhevsky, Alex, Ilya Sutskever, and Geoffrey E. Hinton. "Imagenet classification with deep convolutional neural networks." Communications of the ACM 60.6 (2017): 84-90. [[review link](https://github.com/sooooner/papers/issues/28)]
10. Szegedy, Christian, et al. "Going deeper with convolutions." Proceedings of the IEEE conference on computer vision and pattern recognition. 2015. [[review link](https://github.com/sooooner/papers/issues/29)]
11. He, Kaiming, et al. "Deep residual learning for image recognition." Proceedings of the IEEE conference on computer vision and pattern recognition. 2016. [[review link](https://github.com/sooooner/papers/issues/30)]
12. Wang, Fei, et al. "Residual attention network for image classification." Proceedings of the IEEE conference on computer vision and pattern recognition. 2017. [[review link](https://github.com/sooooner/papers/issues/46)] [[implement link](https://github.com/sooooner/Residual-Attention-Network-with-tensorflow2)]

## Object Detection

1. Girshick, Ross, et al. "Rich feature hierarchies for accurate object detection and semantic segmentation." Proceedings of the IEEE conference on computer vision and pattern recognition. 2014. [[review link](https://github.com/sooooner/papers/issues/32)]
2. Girshick, Ross. "Fast r-cnn." Proceedings of the IEEE international conference on computer vision. 2015. [[review link](https://github.com/sooooner/papers/issues/33)]
3. Ren, Shaoqing, et al. "Faster r-cnn: Towards real-time object detection with region proposal networks." IEEE transactions on pattern analysis and machine intelligence 39.6 (2016): 1137-1149. [[review link](https://github.com/sooooner/papers/issues/8)]
4. Redmon, Joseph, et al. "You only look once: Unified, real-time object detection." Proceedings of the IEEE conference on computer vision and pattern recognition. 2016. [[review link](https://github.com/sooooner/papers/issues/43)]
5. Redmon, Joseph, and Ali Farhadi. "YOLO9000: better, faster, stronger." Proceedings of the IEEE conference on computer vision and pattern recognition. 2017. [[review link](https://github.com/sooooner/papers/issues/44)]
6. Redmon, Joseph, and Ali Farhadi. "Yolov3: An incremental improvement." arXiv preprint arXiv:1804.02767 (2018). [[ link]()]

## Generative model

1. Goodfellow, Ian, et al. "Generative adversarial nets." Advances in neural information processing systems. 2014. [[review link](https://github.com/sooooner/papers/issues/2)] [[implement link](https://github.com/sooooner/GAN-implemented-with-tensorflow2)]
2. Mirza, Mehdi, and Simon Osindero. "Conditional generative adversarial nets." arXiv preprint arXiv:1411.1784 (2014). [[review link](https://github.com/sooooner/papers/issues/34)]
3. Denton, Emily L., Soumith Chintala, and Rob Fergus. "Deep generative image models using an laplacian pyramid of adversarial networks." Advances in neural information processing systems. 2015. [[review link](https://github.com/sooooner/papers/issues/35)]
4. Karras, Tero, et al. "Progressive growing of gans for improved quality, stability, and variation." arXiv preprint arXiv:1710.10196 (2017). [[review link](https://github.com/sooooner/papers/issues/36)]
5. Radford, Alec, Luke Metz, and Soumith Chintala. "Unsupervised representation learning with deep convolutional generative adversarial networks." arXiv preprint arXiv:1511.06434 (2015). [[review link](https://github.com/sooooner/papers/issues/21)]
6. Karras, Tero, Samuli Laine, and Timo Aila. "A style-based generator architecture for generative adversarial networks." Proceedings of the IEEE conference on computer vision and pattern recognition. 2019. [[ link]()]
7. Salimans, Tim, et al. "Improved techniques for training gans." Advances in neural information processing systems 29 (2016): 2234-2242. [[ link]()]
8. Isola, Phillip, et al. "Image-to-image translation with conditional adversarial networks." Proceedings of the IEEE conference on computer vision and pattern recognition. 2017. [[ link]()]
9. Karras, Tero, et al. "Analyzing and improving the image quality of stylegan." Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2020. [[ link]()]
10. Brock, Andrew, Jeff Donahue, and Karen Simonyan. "Large scale gan training for high fidelity natural image synthesis." arXiv preprint arXiv:1809.11096 (2018). [[ link]()]
11. Zhang, Han, et al. "Stackgan: Text to photo-realistic image synthesis with stacked generative adversarial networks." Proceedings of the IEEE international conference on computer vision. 2017. [[ link]()]
12. Zhu, Jun-Yan, et al. "Unpaired image-to-image translation using cycle-consistent adversarial networks." Proceedings of the IEEE international conference on computer vision. 2017. [[ link]()]
13. Kingma, Diederik P., and Max Welling. "Auto-encoding variational bayes." arXiv preprint arXiv:1312.6114 (2013). [[review link](https://github.com/sooooner/papers/issues/7)] [[implement link](https://github.com/sooooner/VAE-implemented-with-tensorflow2)]

## Super Resolution 

1. Dong, Chao, et al. "Image super-resolution using deep convolutional networks." IEEE transactions on pattern analysis and machine intelligence 38.2 (2015): 295-307. [[review link](https://github.com/sooooner/papers/issues/4)]
2. Kim, Jiwon, Jung Kwon Lee, and Kyoung Mu Lee. "Accurate image super-resolution using very deep convolutional networks." Proceedings of the IEEE conference on computer vision and pattern recognition. 2016. [[review link](https://github.com/sooooner/papers/issues/5)]

## NLP

1. Vaswani, Ashish, et al. "Attention is all you need." Advances in neural information processing systems 30 (2017): 5998-6008. [[review link](https://github.com/sooooner/papers/issues/53)]
2. Devlin, Jacob, et al. "Bert: Pre-training of deep bidirectional transformers for language understanding." arXiv preprint arXiv:1810.04805 (2018). [[review link](https://github.com/sooooner/papers/issues/39)]
3. Madabushi, Harish Tayyar, Elena Kochkina, and Michael Castelle. "Cost-Sensitive BERT for Generalisable Sentence Classification with Imbalanced Data." arXiv preprint arXiv:2003.11563 (2020). [[review link](https://github.com/sooooner/papers/issues/54)]
4. Liu, Yinhan, et al. "Roberta: A robustly optimized bert pretraining approach." arXiv preprint arXiv:1907.11692 (2019). [[review link](https://github.com/sooooner/papers/issues/55)]
5. Sutskever, Ilya, Oriol Vinyals, and Quoc V. Le. "Sequence to sequence learning with neural networks." Advances in neural information processing systems 27 (2014): 3104-3112. [[review link](https://github.com/sooooner/papers/issues/57)]
6. Socher, Richard, et al. "Recursive deep models for semantic compositionality over a sentiment treebank." Proceedings of the 2013 conference on empirical methods in natural language processing. 2013. [[ link]()]
7. Bengio, Yoshua, et al. "A neural probabilistic language model." Journal of machine learning research 3.Feb (2003): 1137-1155. [[ link]()]
8. Chung, Junyoung, et al. "Empirical evaluation of gated recurrent neural networks on sequence modeling." arXiv preprint arXiv:1412.3555 (2014). [[ link]()]
9. Cho, Kyunghyun, et al. "On the properties of neural machine translation: Encoder-decoder approaches." arXiv preprint arXiv:1409.1259 (2014). [[ link]()]
10. Cho, Kyunghyun, et al. "Learning phrase representations using RNN encoder-decoder for statistical machine translation." arXiv preprint arXiv:1406.1078 (2014). [[ link]()]
11. Mikolov, Tomáš, Wen-tau Yih, and Geoffrey Zweig. "Linguistic regularities in continuous space word representations." Proceedings of the 2013 conference of the north american chapter of the association for computational linguistics: Human language technologies. 2013. [[ link]()]
12. Wei, Jason, and Kai Zou. "Eda: Easy data augmentation techniques for boosting performance on text classification tasks." arXiv preprint arXiv:1901.11196 (2019). [[review link](https://github.com/sooooner/papers/issues/40)]
13. **Lin, Tianyang, et al. "A Survey of Transformers." arXiv preprint arXiv:2106.04554 (2021).** [[review link](https://github.com/sooooner/papers/issues/52)]

## Word embedding

1. Mikolov, Tomas, et al. "Distributed representations of words and phrases and their compositionality." Advances in neural information processing systems 26 (2013): 3111-3119. [[review link](https://github.com/sooooner/papers/issues/41)]
2. Mikolov, Tomas, et al. "Efficient estimation of word representations in vector space." arXiv preprint arXiv:1301.3781 (2013). [[ link]()]
3. Goldberg, Yoav, and Omer Levy. "word2vec Explained: deriving Mikolov et al.'s negative-sampling word-embedding method." arXiv preprint arXiv:1402.3722 (2014). [[ link]()]
4. Le, Quoc, and Tomas Mikolov. "Distributed representations of sentences and documents." International conference on machine learning. 2014. [[ link]()]
5. Patel, Kevin, and Pushpak Bhattacharyya. "Towards lower bounds on number of dimensions for word embeddings." Proceedings of the Eighth International Joint Conference on Natural Language Processing (Volume 2: Short Papers). 2017. [[ link]()]
6. Yin, Zi, and Yuanyuan Shen. "On the dimensionality of word embedding." Advances in neural information processing systems 31 (2018): 887-898. [[ link]()]
7. Wang, Yu. "Single Training Dimension Selection for Word Embedding with PCA." arXiv preprint arXiv:1909.01761 (2019). [[ link]()]
8. Mu, Jiaqi, Suma Bhat, and Pramod Viswanath. "Representing sentences as low-rank subspaces." arXiv preprint arXiv:1704.05358 (2017). [[ link]()]
9. Kenter, Tom, and Maarten De Rijke. "Short text similarity with word embeddings." Proceedings of the 24th ACM international on conference on information and knowledge management. 2015. [[review link](https://dl.acm.org/doi/10.1145/2806416.2806475)]
10. Pennington, Jeffrey, Richard Socher, and Christopher D. Manning. "Glove: Global vectors for word representation." Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP). 2014. [[ link]()]
11. Peters, Matthew E., et al. "Deep contextualized word representations." arXiv preprint arXiv:1802.05365 (2018). [[ link]()]

## GPT

1. Radford, Alec, et al. "Improving language understanding by generative pre-training." (2018): 12. [[review link](https://github.com/sooooner/papers/issues/48)]
2. Radford, Alec, et al. "Language models are unsupervised multitask learners." OpenAI blog 1.8 (2019): 9. [[review link](https://github.com/sooooner/papers/issues/49)]

## Recommendation

1. Covington, Paul, Jay Adams, and Emre Sargin. "Deep neural networks for youtube recommendations." Proceedings of the 10th ACM conference on recommender systems. 2016. [[review link](https://github.com/sooooner/papers/issues/37)]
2. Davidson, James, et al. "The YouTube video recommendation system." Proceedings of the fourth ACM conference on Recommender systems. 2010. [[ link]()]
3. He, Xiangnan, et al. "Neural collaborative filtering." Proceedings of the 26th international conference on world wide web. 2017. [[ link]()]
4. Zhang, Tingting, et al. "Feature-level Deeper Self-Attention Network for Sequential Recommendation." IJCAI. 2019. [[ link]()]
5. Sun, Limei, et al. "A Time-Sensitive Collaborative Filtering Model in Recommendation Systems." 2016 IEEE International Conference on Internet of Things (iThings) and IEEE Green Computing and Communications (GreenCom) and IEEE Cyber, Physical and Social Computing (CPSCom) and IEEE Smart Data (SmartData). IEEE, 2016. [[ link]()]
6. He, Ruining, and Julian McAuley. "Ups and downs: Modeling the visual evolution of fashion trends with one-class collaborative filtering." proceedings of the 25th international conference on world wide web. 2016. [[ link]()]
7. Koren, Yehuda. "Collaborative filtering with temporal dynamics." Proceedings of the 15th ACM SIGKDD international conference on Knowledge discovery and data mining. 2009. [[ link]()]
8. Wu, Liwei. "Advances in Collaborative Filtering and Ranking." arXiv preprint arXiv:2002.12312 (2020). [[ link]()]
9. Koren, Yehuda. "Factorization meets the neighborhood: a multifaceted collaborative filtering model." Proceedings of the 14th ACM SIGKDD international conference on Knowledge discovery and data mining. 2008. [[ link]()]
10. Bell, Robert M., and Yehuda Koren. "Scalable collaborative filtering with jointly derived neighborhood interpolation weights." Seventh IEEE International Conference on Data Mining (ICDM 2007). IEEE, 2007. [[ link]()]
11. Paterek, Arkadiusz. "Improving regularized singular value decomposition for collaborative filtering." Proceedings of KDD cup and workshop. Vol. 2007. 2007. [[ link]()]

### recommender system the textbook[[review link](https://github.com/sooooner/recommender-system)]

## TF-IDF

1. Al-Taie, Mohammed Zuhair, Siti Mariyam Shamsuddin, and Joel Pinho Lucas. "Predicting the Relevance of Search Results for E-Commerce Systems." Int. J. Advance Soft Compu. Appl 7.3 (2015). [[ link]()]
2. Mandhula, Trupthi, Suresh Pabboju, and Narsimha Gugulotu. "Predicting the customer’s opinion on amazon products using selective memory architecture-based convolutional neural network." The Journal of Supercomputing (2019): 1-25. [[ link]()]
3. Ramos, Juan. "Using tf-idf to determine word relevance in document queries." Proceedings of the first instructional conference on machine learning. Vol. 242. 2003. [[ link]()]
4. Das, Bijoyan, and Sarit Chakraborty. "An improved text sentiment classification model using TF-IDF and next word negation." arXiv preprint arXiv:1806.06407 (2018). [[ link]()]
5. Tongman, Sasiporn, and Niwan Wattanakitrungroj. "Classifying Positive or Negative Text Using Features Based on Opinion Words and Term Frequency-Inverse Document Frequency." 2018 5th International Conference on Advanced Informatics: Concept Theory and Applications (ICAICTA). IEEE, 2018. [[ link]()]
6. Zhao, Jiang, Man Lan, and Junfeng Tian. "Ecnu: Using traditional similarity measurements and word embedding for semantic textual similarity estimation." Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval 2015). 2015. [[ link]()]
7. Júnior, Edilson Anselmo Corrêa, Vanessa Queiroz Marinho, and Leandro Borges dos Santos. "NILC-USP at semeval-2017 task 4: A multi-view ensemble for twitter sentiment analysis." Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017). 2017. [[ link]()]

## Ad-hoc
[[project github link](https://tnsgh0101.medium.com/query-document-relevence-ranking-model-2-b50af71b2ca7)]

1. McDonald, Ryan, Georgios-Ioannis Brokos, and Ion Androutsopoulos. "Deep relevance ranking using enhanced document-query interactions." arXiv preprint arXiv:1809.01682 (2018). [[project review link](https://tnsgh0101.medium.com/query-document-relevence-ranking-model-596c8571b84)]
2. Hui, Kai, et al. "Pacrr: A position-aware neural ir model for relevance matching." arXiv preprint arXiv:1704.03940 (2017). [[project review link](https://tnsgh0101.medium.com/query-document-relevence-ranking-model-2-b50af71b2ca7)] 
3. Guo, Jiafeng, et al. "A deep relevance matching model for ad-hoc retrieval." Proceedings of the 25th ACM International on Conference on Information and Knowledge Management. 2016. [[project review link](https://github.com/sooooner/Query-Document-Relevance-Ranking-model)]
4. MacAvaney, Sean, et al. "CEDR: Contextualized embeddings for document ranking." Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval. 2019. [[project review link](https://tnsgh0101.medium.com/query-document-relevance-ranking-model-3-9305028cf44)]
5. Li, Canjia, et al. "PARADE: Passage representation aggregation for document reranking." arXiv preprint arXiv:2008.09093 (2020). [[ link]()]

## Information Retrieval

1. Berry, Michael W., Susan T. Dumais, and Gavin W. O’Brien. "Using linear algebra for intelligent information retrieval." SIAM review 37.4 (1995): 573-595. [[ link]()]
2. Nigam, Priyanka, et al. "Semantic product search." Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining. 2019. [[ link]()]
    - amazon Information Retrieval paper, product의 속성(색, 브랜드 등등)을 inputs으로 넣어줌
3. Ingyu Choi, Jason, et al. "Semantic Product Search for Matching Structured Product Catalogs in E-Commerce." arXiv e-prints (2020): arXiv-2008. [[ link]()]

## Learning To Ranking

1. Dong, Xishuang, et al. "An overview of learning to rank for information retrieval." 2009 WRI World Congress on Computer Science and Information Engineering. Vol. 3. IEEE, 2009. [[review link](https://github.com/sooooner/papers/issues/56)]
2. Liu, Tie-Yan. Learning to rank for information retrieval. Springer Science & Business Media, 2011. [[ link]()]
3. Pei, Changhua, et al. "Personalized re-ranking for recommendation." Proceedings of the 13th ACM Conference on Recommender Systems. 2019. [[review link](https://github.com/sooooner/papers/issues/47)]

## Reinforcement Learning

1. Mnih, Volodymyr, et al. "Playing atari with deep reinforcement learning." arXiv preprint arXiv:1312.5602 (2013). [[review link](https://github.com/sooooner/papers/issues/1)]


## Others

2. Lee, Juhyun, et al. "On-device neural net inference with mobile gpus." arXiv preprint arXiv:1907.01989 (2019). [[ link]()]